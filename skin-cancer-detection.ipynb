{"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":6563780,"sourceType":"datasetVersion","datasetId":3792263}],"dockerImageVersionId":30746,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input/melanoma/Skin cancer ISIC The International Skin Imaging Collaboration'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"id":"D_UEeBZ8aY4I","outputId":"3cfab481-179e-43c8-ce56-cb5c4d2d95d4","executionInfo":{"status":"ok","timestamp":1678132633541,"user_tz":-330,"elapsed":3589,"user":{"displayName":"LOKESWAR M 20BCE1825","userId":"00380158805171448125"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pathlib\nimport os\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nimport PIL\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.models import Sequential\n\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import ModelCheckpoint,EarlyStopping\n\nfrom tensorflow.keras.preprocessing.image import load_img","metadata":{"id":"tvmDB--Fb9ie"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_dir_train = pathlib.Path(\"/kaggle/input/melanoma/Skin cancer ISIC The International Skin Imaging Collaboration/Train\")\ndata_dir_test = pathlib.Path(\"/kaggle/input/melanoma/Skin cancer ISIC The International Skin Imaging Collaboration/Test\")","metadata":{"id":"28Dj1SQlcDxd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_count_train = len(list(data_dir_train.glob('*/*.jpg')))\nprint(image_count_train)\n\nimage_count_test = len(list(data_dir_test.glob('*/*.jpg')))\nprint(image_count_test)","metadata":{"id":"QxpxJgGgcH27","outputId":"cdb89755-9e00-4573-d5f4-730a171bc3e1","executionInfo":{"status":"ok","timestamp":1678122080185,"user_tz":-330,"elapsed":25,"user":{"displayName":"LOKESWAR M 20BCE1825","userId":"00380158805171448125"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_dataset = tf.keras.preprocessing.image_dataset_from_directory(data_dir_train,batch_size=32,image_size=(180,180),\n                                                                    label_mode='categorical',seed=123)\n\nclass_names = image_dataset.class_names\n\nfiles_path_dict = {}\n\nfor c in class_names:\n    files_path_dict[c] = list(map(lambda x:str(data_dir_train)+'/'+c+'/'+x,os.listdir(str(data_dir_train)+'/'+c)))\n\nplt.figure(figsize=(15,15))\nindex = 0\nfor c in class_names:\n    path_list = files_path_dict[c][:1]\n    index += 1\n    plt.subplot(3,3,index)\n    plt.imshow(load_img(path_list[0],target_size=(180,180)))\n    plt.title(c)\n    plt.axis(\"off\")","metadata":{"id":"L4TA-RUxcLFM","outputId":"015b8135-ecef-4de4-d8b4-aac4f1c3812f","executionInfo":{"status":"ok","timestamp":1678122084724,"user_tz":-330,"elapsed":4561,"user":{"displayName":"LOKESWAR M 20BCE1825","userId":"00380158805171448125"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def class_distribution_count(directory):\n\n    count= []\n    for path in pathlib.Path(directory).iterdir():\n        if path.is_dir():\n            count.append(len([name for name in os.listdir(path)\n                               if os.path.isfile(os.path.join(path, name))]))\n\n    #name of the classes\n    sub_directory = [name for name in os.listdir(directory)\n                    if os.path.isdir(os.path.join(directory, name))]\n\n    #return dataframe with image count and class.\n    return pd.DataFrame(list(zip(sub_directory,count)),columns =['Class', 'No. of Image'])\n\ndf = class_distribution_count(data_dir_train)\ndf","metadata":{"id":"aIH8DAqrcRV_","outputId":"0cf734f4-d3f8-44a6-cc1b-d362ec7edb57","executionInfo":{"status":"ok","timestamp":1678122084725,"user_tz":-330,"elapsed":7,"user":{"displayName":"LOKESWAR M 20BCE1825","userId":"00380158805171448125"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Visualize the Number of image in each class.\nimport seaborn as sns\nplt.figure(figsize=(10, 8))\nsns.barplot(x=\"No. of Image\", y=\"Class\", data=df,\n            label=\"Class\")","metadata":{"id":"Z6apTxw9cUsE","outputId":"f488d764-b32d-4c0e-9468-41b2f8ba71a5","executionInfo":{"status":"ok","timestamp":1678122085655,"user_tz":-330,"elapsed":936,"user":{"displayName":"LOKESWAR M 20BCE1825","userId":"00380158805171448125"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#install Augmentor\n!pip install Augmentor","metadata":{"id":"e96q53_Mcaj3","outputId":"0a164448-ba71-46a4-884f-36daf333e270","executionInfo":{"status":"ok","timestamp":1678122088958,"user_tz":-330,"elapsed":3308,"user":{"displayName":"LOKESWAR M 20BCE1825","userId":"00380158805171448125"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path_to_training_dataset=\"/kaggle/input/melanoma/Skin cancer ISIC The International Skin Imaging Collaboration/Train\"\nimport Augmentor\nfor i in class_names:\n    p = Augmentor.Pipeline(path_to_training_dataset + i)\n    p.rotate(probability=0.7, max_left_rotation=10, max_right_rotation=10)\n    p.sample(500)  #Adding 500 samples per class to make sure that none of the classes are sparse","metadata":{"id":"vt1h7nYvcgll","outputId":"e80657db-56d8-48b4-ff05-06cd1eece213","executionInfo":{"status":"ok","timestamp":1678122569162,"user_tz":-330,"elapsed":480213,"user":{"displayName":"LOKESWAR M 20BCE1825","userId":"00380158805171448125"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Count total number of image generated by Augmentor.\nimage_count_train = len(list(data_dir_train.glob('*/output/*.jpg')))\nprint(image_count_train)","metadata":{"id":"1Brs_qcqehQa","outputId":"e238a527-f206-4af1-9baf-9a205a5d7ae6","executionInfo":{"status":"ok","timestamp":1678122569849,"user_tz":-330,"elapsed":702,"user":{"displayName":"LOKESWAR M 20BCE1825","userId":"00380158805171448125"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train dataset\ntrain_ds = tf.keras.preprocessing.image_dataset_from_directory(data_dir_train, batch_size=32,\n                                                               image_size=(180,180), label_mode='categorical',\n                                                               seed=123,subset=\"training\",\n                                                               validation_split=0.2)\n\n#label_mode is categorial, the labels are a float32 tensor of shape (batch_size, num_classes),\n#representing a one-hot encoding of the class index.","metadata":{"id":"EGtn2jz-eklr","outputId":"319161fa-4701-458b-c5ed-ae0407af0f10","executionInfo":{"status":"ok","timestamp":1678122569850,"user_tz":-330,"elapsed":6,"user":{"displayName":"LOKESWAR M 20BCE1825","userId":"00380158805171448125"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# validation dataset\nval_ds =tf.keras.preprocessing.image_dataset_from_directory(data_dir_train,batch_size=32,\n                                                            image_size=(180,180), label_mode='categorical',\n                                                            seed=123,subset=\"validation\",\n                                                            validation_split=0.2)","metadata":{"id":"SE0SkZE4enLD","outputId":"aa5e5dd0-2f58-447a-d307-b90997ec1ca6","executionInfo":{"status":"ok","timestamp":1678122570219,"user_tz":-330,"elapsed":372,"user":{"displayName":"LOKESWAR M 20BCE1825","userId":"00380158805171448125"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"AUTOTUNE = tf.data.experimental.AUTOTUNE\ntrain_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\nval_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)","metadata":{"id":"eCOI85RteqgV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Sequential()\n\nmodel.add(layers.experimental.preprocessing.Rescaling(1./255,input_shape=(180,180,3)))   #Rescaling Layer\n\n#First Convulation layer\nmodel.add(layers.Conv2D(32,kernel_size=(3,3),activation='relu'))\nmodel.add(layers.MaxPool2D(pool_size=(2,2)))\n\n#Second Convulation Layer\nmodel.add(layers.Conv2D(64,kernel_size=(3,3),activation='relu'))\nmodel.add(layers.MaxPool2D(pool_size=(2,2)))\n\n#Third Convulation Layer\nmodel.add(layers.Conv2D(128,kernel_size=(3,3),activation='relu'))\nmodel.add(layers.MaxPool2D(pool_size=(2,2)))\n\n#Dropout layer with 50% Fraction of the input units to drop.\nmodel.add(layers.Dropout(0.5))\n\n#Flatten Layer\n##Keras.layers.flatten function flattens the multi-dimensional input tensors into a single dimension.\nmodel.add(layers.Flatten())\n\n#Dense Layer\nmodel.add(layers.Dense(128,activation='relu'))\n\n#Dropout layer with 25% Fraction of the input units to drop.\nmodel.add(layers.Dropout(0.25))\n\n#Dense Layer with softmax activation function.\n#Softmax is an activation function that scales numbers/logits into probabilities.\nmodel.add(layers.Dense(len(class_names),activation='softmax'))\n\nmodel.summary()","metadata":{"id":"t2QQxEpJes84","outputId":"a0ea4db7-019a-4ad5-f0d6-906d43613eed","executionInfo":{"status":"ok","timestamp":1678122572345,"user_tz":-330,"elapsed":2131,"user":{"displayName":"LOKESWAR M 20BCE1825","userId":"00380158805171448125"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# vizualizing the model\nfrom tensorflow.keras.utils import plot_model\nplot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)","metadata":{"id":"_iAOTuBxey_3","outputId":"9bf3202f-d891-4b0b-f4b6-bf0120cb86e8","executionInfo":{"status":"ok","timestamp":1678122572345,"user_tz":-330,"elapsed":13,"user":{"displayName":"LOKESWAR M 20BCE1825","userId":"00380158805171448125"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Compile the Model\n\n#Adam optimization: is a stochastic gradient descent method that is based on adaptive estimation of first-order and second-order moments.\n#categorical_crossentropy: Used as a loss function for multi-class classification model where there are two or more output labels.\n\nmodel.compile(optimizer=\"Adam\",loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])\n\n#ModelCheckpoint callback is used in conjunction with training using model.fit() to save a model or weights (in a checkpoint file) at some interval,\n#so the model or weights can be loaded later to continue the training from the state saved.\ncheckpoint = ModelCheckpoint(\"model.h5\",monitor=\"val_accuracy\",save_best_only=True,mode=\"auto\",verbose=1)\n\n#Stop training when a monitored metric has stopped improving.\nearlystop = EarlyStopping(monitor=\"val_accuracy\",patience=5,mode=\"auto\",verbose=1)","metadata":{"id":"XNgyjYOre3Bb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train the model\nepochs = 20\nhistory = model.fit(train_ds, validation_data=val_ds, epochs=epochs,callbacks=[checkpoint,earlystop])","metadata":{"id":"Qj6ZS0Lne6wg","outputId":"db4005d6-424f-4a7d-d3a9-d5d1d856823f","executionInfo":{"status":"ok","timestamp":1678132210257,"user_tz":-330,"elapsed":5189099,"user":{"displayName":"LOKESWAR M 20BCE1825","userId":"00380158805171448125"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot the training curves\n\nepochs_range = range(earlystop.stopped_epoch+1)\n\nplt.figure(figsize=(15, 10))\nplt.subplot(1, 2, 1)\n\n#Plot Model Accuracy\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel(epochs_range)\nplt.legend(['train', 'val'], loc='upper left')\n\n#Plot Model Loss\nplt.subplot(1, 2, 2)\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel(epochs_range)\nplt.legend(['train', 'val'], loc='upper left')\nplt.show()\n","metadata":{"id":"q6V1plISEBqO","outputId":"9ac77535-d09b-40c8-fae2-a1953ad4c4a3","executionInfo":{"status":"ok","timestamp":1678132211546,"user_tz":-330,"elapsed":1288,"user":{"displayName":"LOKESWAR M 20BCE1825","userId":"00380158805171448125"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from glob import glob\nTest_image_path = os.path.join(data_dir_test, class_names[1], '*')\nTest_image = glob(Test_image_path)\nTest_image = load_img(Test_image[-1],target_size=(180,180,3))\nplt.imshow(Test_image)\nplt.grid(False)\n\nimg = np.expand_dims(Test_image,axis=0)\npred = model.predict(img)\npred = np.argmax(pred)\npred_class = class_names[pred]\nprint(\"Actual Class \"+ class_names[1] +'\\n'+ \"Predictive Class \"+pred_class )","metadata":{"id":"CTPWrTWNEFJ8","outputId":"2c82ac0c-a409-42fd-d849-e322f76f975b","executionInfo":{"status":"ok","timestamp":1678132212855,"user_tz":-330,"elapsed":1310,"user":{"displayName":"LOKESWAR M 20BCE1825","userId":"00380158805171448125"}}},"execution_count":null,"outputs":[]}]}